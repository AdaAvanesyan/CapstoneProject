{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üì¶ Data Preprocessing: Unified Cell (Google Colab)\n",
        "# ==========================\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import librosa\n",
        "\n",
        "# Logging helper\n",
        "def log(msg):\n",
        "    print(f\"[INFO] {msg}\")\n",
        "\n",
        "# Main preprocessing function\n",
        "def extract_and_label_data_colab(ravdess_zip, cremad_zip, extract_root, save_path=None, preview=True):\n",
        "    \"\"\"\n",
        "    Extracts audio files from ZIPs, parses emotion labels, performs cleaning,\n",
        "    and returns a labeled DataFrame. Saves to CSV if path is provided.\n",
        "    \"\"\"\n",
        "\n",
        "    # Setup directories\n",
        "    ravdess_path = os.path.join(extract_root, \"ravdess\")\n",
        "    cremad_path = os.path.join(extract_root, \"cremad\")\n",
        "    os.makedirs(ravdess_path, exist_ok=True)\n",
        "    os.makedirs(cremad_path, exist_ok=True)\n",
        "\n",
        "    # Extract ZIP files\n",
        "    log(\"Extracting RAVDESS...\")\n",
        "    with zipfile.ZipFile(ravdess_zip, 'r') as zip_ref:\n",
        "        zip_ref.extractall(ravdess_path)\n",
        "\n",
        "    log(\"Extracting CREMA-D...\")\n",
        "    with zipfile.ZipFile(cremad_zip, 'r') as zip_ref:\n",
        "        zip_ref.extractall(cremad_path)\n",
        "\n",
        "    target_emotions = ['happy', 'sad', 'neutral', 'angry']\n",
        "\n",
        "    # Parse emotion from filename\n",
        "    def parse_ravdess(filename):\n",
        "        try:\n",
        "            code = int(filename.split('-')[2])\n",
        "            return {1: 'neutral', 3: 'happy', 4: 'sad', 5: 'angry'}.get(code)\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    def parse_cremad(filename):\n",
        "        try:\n",
        "            code = filename.split('_')[2]\n",
        "            return {'ANG': 'angry', 'HAP': 'happy', 'NEU': 'neutral', 'SAD': 'sad'}.get(code)\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    # Collect metadata\n",
        "    ravdess_data = []\n",
        "    for root, _, files in os.walk(ravdess_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.wav'):\n",
        "                emotion = parse_ravdess(file)\n",
        "                full_path = os.path.join(root, file)\n",
        "                if emotion in target_emotions:\n",
        "                    ravdess_data.append({\n",
        "                        'file_path': full_path,\n",
        "                        'emotion': emotion,\n",
        "                        'dataset': 'RAVDESS'\n",
        "                    })\n",
        "\n",
        "    cremad_data = []\n",
        "    for root, _, files in os.walk(cremad_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.wav'):\n",
        "                emotion = parse_cremad(file)\n",
        "                full_path = os.path.join(root, file)\n",
        "                if emotion in target_emotions:\n",
        "                    cremad_data.append({\n",
        "                        'file_path': full_path,\n",
        "                        'emotion': emotion,\n",
        "                        'dataset': 'CREMA-D'\n",
        "                    })\n",
        "\n",
        "    df = pd.DataFrame(ravdess_data + cremad_data)\n",
        "    log(f\"Initial size: {df.shape}\")\n",
        "\n",
        "    # ========================\n",
        "    # ‚úÖ Data Cleaning\n",
        "    # ========================\n",
        "\n",
        "    # Drop nulls\n",
        "    df.dropna(subset=['file_path', 'emotion'], inplace=True)\n",
        "\n",
        "    # Remove missing or broken files\n",
        "    df = df[df['file_path'].apply(lambda x: os.path.exists(x))]\n",
        "\n",
        "    # Remove files < 1 sec (optional quality check)\n",
        "    def is_valid_duration(path, min_sec=1.0):\n",
        "        try:\n",
        "            duration = librosa.get_duration(path=path)\n",
        "            return duration >= min_sec\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    df = df[df['file_path'].apply(is_valid_duration)]\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Show stats\n",
        "    if preview:\n",
        "        log(\"‚úÖ Sample rows:\")\n",
        "        print(df.head())\n",
        "        log(\"üìä Emotion distribution:\")\n",
        "        print(df['emotion'].value_counts())\n",
        "        log(\"üìÇ Dataset distribution:\")\n",
        "        print(df['dataset'].value_counts())\n",
        "\n",
        "    # Save to CSV\n",
        "    if save_path:\n",
        "        df.to_csv(save_path, index=False)\n",
        "        log(f\"üìÅ Saved to: {save_path}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# ================\n",
        "# ‚úÖ Run It\n",
        "# ================\n",
        "df = extract_and_label_data_colab(\n",
        "    ravdess_zip=\"/content/drive/MyDrive/capstone_data/archive.zip\",\n",
        "    cremad_zip=\"/content/drive/MyDrive/capstone_data/crema.zip\",\n",
        "    extract_root=\"/content/dataset\",\n",
        "    save_path=\"/content/drive/MyDrive/capstone_data/combined_clean_metadata.csv\",\n",
        "    preview=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-hK9C5XVjKI",
        "outputId": "cf111b43-a573-4660-e412-bda922105337"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[INFO] Extracting RAVDESS...\n",
            "[INFO] Extracting CREMA-D...\n",
            "[INFO] Initial size: (6244, 3)\n",
            "[INFO] ‚úÖ Sample rows:\n",
            "                                           file_path emotion  dataset\n",
            "0  /content/dataset/ravdess/Actor_15/03-01-05-02-...   angry  RAVDESS\n",
            "1  /content/dataset/ravdess/Actor_15/03-01-05-02-...   angry  RAVDESS\n",
            "2  /content/dataset/ravdess/Actor_15/03-01-03-02-...   happy  RAVDESS\n",
            "3  /content/dataset/ravdess/Actor_15/03-01-03-01-...   happy  RAVDESS\n",
            "4  /content/dataset/ravdess/Actor_15/03-01-03-02-...   happy  RAVDESS\n",
            "[INFO] üìä Emotion distribution:\n",
            "emotion\n",
            "angry      1655\n",
            "happy      1655\n",
            "sad        1655\n",
            "neutral    1279\n",
            "Name: count, dtype: int64\n",
            "[INFO] üìÇ Dataset distribution:\n",
            "dataset\n",
            "CREMA-D    4900\n",
            "RAVDESS    1344\n",
            "Name: count, dtype: int64\n",
            "[INFO] üìÅ Saved to: /content/drive/MyDrive/capstone_data/combined_clean_metadata.csv\n"
          ]
        }
      ]
    }
  ]
}