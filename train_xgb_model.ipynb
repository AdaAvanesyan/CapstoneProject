{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kuvcfb7KtIyJ"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# ðŸš€ Train XGBoost Model (Final Version with Best Known Params)\n",
        "# ================================\n",
        "\n",
        "\"\"\"\n",
        "This notebook trains the XGBoost model using the best hyperparameters\n",
        "found previously through GridSearchCV:\n",
        "  - max_depth = 8\n",
        "  - n_estimators = 200\n",
        "  - learning_rate = default (None)\n",
        "\n",
        "To reduce training time in Google Colab (CPU-only), this version skips\n",
        "GridSearch and directly trains with those final parameters.\n",
        "\n",
        "Outputs:\n",
        "- Trained model (`xgb_model.joblib`)\n",
        "- Classification report\n",
        "\"\"\"\n",
        "\n",
        "# ðŸ“¦ Imports\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from xgboost import XGBClassifier\n",
        "import joblib\n",
        "\n",
        "# âœ… Load Features and Labels\n",
        "X = np.load(\"/content/drive/MyDrive/capstone_data/x_xgb_features.npy\")\n",
        "y = np.load(\"/content/drive/MyDrive/capstone_data/y_xgb_labels.npy\")\n",
        "\n",
        "print(f\"[INFO] Loaded X shape: {X.shape}\")\n",
        "print(f\"[INFO] Loaded y shape: {y.shape}\")\n",
        "\n",
        "# âœ… Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# âœ… Directly Train with Best Params\n",
        "print(\"[INFO] Training with best-known parameters: max_depth=8, n_estimators=200\")\n",
        "xgb = XGBClassifier(\n",
        "    max_depth=8,\n",
        "    n_estimators=200,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=42\n",
        ")\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "# âœ… Evaluate\n",
        "y_pred = xgb.predict(X_test)\n",
        "print(\"\\nðŸ“Š Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# âœ… Save Model\n",
        "MODEL_PATH = \"/content/drive/MyDrive/capstone_data/xgb_model.joblib\"\n",
        "joblib.dump(xgb, MODEL_PATH)\n",
        "print(f\"[âœ…] XGBoost model saved to: {MODEL_PATH}\")"
      ]
    }
  ]
}