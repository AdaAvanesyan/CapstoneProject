# CapstoneProject

A complete voice-based system that detects human emotions from speech and generates empathetic replies using OpenAI's GPT-3.5-turbo. It combines classical machine learning (XGBoost), deep learning (CNN), and a natural language chatbot into a user-friendly Streamlit interface.

---

## Features

- Upload `.wav` files and detect emotions
- Choose between **XGBoost** (flattened MFCC) and **CNN** (2D MFCC) models
- Generate empathetic responses using **GPT-3.5-turbo**
- Maintain chat memory and emotion context
- Deploy using **Streamlit**

---

## ğŸ“ Project Structure

```
emotion-aware-chatbot/
â”œâ”€â”€ data_preprocessing/             # Clean and label data
â”œâ”€â”€ xgboost_pipeline/
â”‚   â”œâ”€â”€ feature_extraction_xgb.ipynb
â”‚   â”œâ”€â”€ train_xgb_model.ipynb
â”‚   â”œâ”€â”€ evaluate_xgb_model.ipynb
â”œâ”€â”€ cnn_pipeline/
â”‚   â”œâ”€â”€ feature_extraction_cnn.ipynb
â”‚   â”œâ”€â”€ train_cnn_model.ipynb
â”‚   â”œâ”€â”€ evaluate_cnn_model.ipynb
â”œâ”€â”€ predict_and_chatbot.ipynb     # Upload audio + predict + GPT reply
â”œâ”€â”€ app.py                          # Streamlit interface
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
```
##  Run data_preprocessing.ipynb
- Mount Google Drive
- Extract both datasets
- Label and clean files
- Output:
- /content/drive/MyDrive/capstone_data/combined_clean_metadata.csv
